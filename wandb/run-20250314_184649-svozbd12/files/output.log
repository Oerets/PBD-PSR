Fold 2 | Epoch [1/80] | Train Loss: 0.0234 | Val Loss: 0.0253 | R2: -0.4670 | Pearson: -0.0386 | Best Correlation : -0.0386 | Best Epoch : 0
Fold 2 | Epoch [2/80] | Train Loss: 0.0179 | Val Loss: 0.0169 | R2: 0.0204 | Pearson: 0.2955 | Best Correlation : 0.2955 | Best Epoch : 1
Process Process-2:
Traceback (most recent call last):
  File "C:\Users\hyunoh\anaconda3\envs\spine\lib\multiprocessing\process.py", line 315, in _bootstrap
    self.run()
  File "C:\Users\hyunoh\anaconda3\envs\spine\lib\multiprocessing\process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "C:\Users\hyunoh\Documents\Codes\BMD_code\cross-validation.py", line 50, in train_fold
    train_loss = train_one_epoch(model, train_loader, optimizer, criterion, device)
  File "C:\Users\hyunoh\Documents\Codes\BMD_code\cross-validation.py", line 88, in train_one_epoch
    optimizer.step()
  File "C:\Users\hyunoh\anaconda3\envs\spine\lib\site-packages\torch\optim\lr_scheduler.py", line 130, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
  File "C:\Users\hyunoh\anaconda3\envs\spine\lib\site-packages\torch\optim\optimizer.py", line 484, in wrapper
    out = func(*args, **kwargs)
  File "C:\Users\hyunoh\anaconda3\envs\spine\lib\site-packages\torch\optim\optimizer.py", line 89, in _use_grad
    ret = func(self, *args, **kwargs)
  File "C:\Users\hyunoh\anaconda3\envs\spine\lib\site-packages\torch\optim\adamw.py", line 227, in step
    adamw(
  File "C:\Users\hyunoh\anaconda3\envs\spine\lib\site-packages\torch\optim\optimizer.py", line 161, in maybe_fallback
    return func(*args, **kwargs)
  File "C:\Users\hyunoh\anaconda3\envs\spine\lib\site-packages\torch\optim\adamw.py", line 767, in adamw
    func(
  File "C:\Users\hyunoh\anaconda3\envs\spine\lib\site-packages\torch\optim\adamw.py", line 518, in _multi_tensor_adamw
    torch._foreach_add_(
KeyboardInterrupt
