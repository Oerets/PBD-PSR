Epoch [1/80] | Train Loss: 0.0235 | Val Loss: 0.0185 | R2: -0.0820 | Pearson: 0.0002
Epoch [2/80] | Train Loss: 0.0175 | Val Loss: 0.0259 | R2: -0.5205 | Pearson: 0.4450
Epoch [3/80] | Train Loss: 0.0154 | Val Loss: 0.0336 | R2: -0.9656 | Pearson: 0.3671
Epoch [4/80] | Train Loss: 0.0142 | Val Loss: 0.0222 | R2: -0.2998 | Pearson: 0.3901
Epoch [5/80] | Train Loss: 0.0127 | Val Loss: 0.0316 | R2: -0.8569 | Pearson: -0.0180
Epoch [6/80] | Train Loss: 0.0105 | Val Loss: 0.0172 | R2: -0.0115 | Pearson: 0.4888
Epoch [7/80] | Train Loss: 0.0078 | Val Loss: 0.0459 | R2: -1.6943 | Pearson: 0.1831
Epoch [8/80] | Train Loss: 0.0061 | Val Loss: 0.0177 | R2: -0.0380 | Pearson: 0.2973
Epoch [9/80] | Train Loss: 0.0050 | Val Loss: 0.0152 | R2: 0.1060 | Pearson: 0.3538
Epoch [10/80] | Train Loss: 0.0034 | Val Loss: 0.0583 | R2: -2.4042 | Pearson: -0.0288
Epoch [11/80] | Train Loss: 0.0034 | Val Loss: 0.0210 | R2: -0.2316 | Pearson: 0.0149
Epoch [12/80] | Train Loss: 0.0028 | Val Loss: 0.0234 | R2: -0.3727 | Pearson: 0.2510
Traceback (most recent call last):
  File "train.py", line 128, in <module>
    train_5_fold(dataset, batch_size=4, epochs=80, learning_rate=0.00005, optimizer_type='AdamW', scheduler_type='CosineAnnealingLR', device='cuda')
  File "train.py", line 50, in train_5_fold
    train_loss = train_one_epoch(model, train_loader, optimizer, criterion, device)
  File "train.py", line 93, in train_one_epoch
    loss.backward()
  File "C:\Users\hyunoh\anaconda3\envs\spine\lib\site-packages\torch\_tensor.py", line 521, in backward
    torch.autograd.backward(
  File "C:\Users\hyunoh\anaconda3\envs\spine\lib\site-packages\torch\autograd\__init__.py", line 289, in backward
    _engine_run_backward(
  File "C:\Users\hyunoh\anaconda3\envs\spine\lib\site-packages\torch\autograd\graph.py", line 769, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
