Epoch [1/80] | Train Loss: 0.0340 | Val Loss: 0.1983 | R2: -10.5776 | Pearson: -0.0097
Epoch [2/80] | Train Loss: 0.0158 | Val Loss: 0.0165 | R2: 0.0337 | Pearson: 0.3589
Epoch [3/80] | Train Loss: 0.0143 | Val Loss: 0.0262 | R2: -0.5235 | Pearson: 0.2938
Epoch [4/80] | Train Loss: 0.0135 | Val Loss: 0.0157 | R2: 0.0877 | Pearson: 0.3430
Epoch [5/80] | Train Loss: 0.0119 | Val Loss: 0.0302 | R2: -0.7728 | Pearson: 0.2785
Epoch [6/80] | Train Loss: 0.0106 | Val Loss: 0.0219 | R2: -0.2777 | Pearson: 0.3284
Epoch [7/80] | Train Loss: 0.0095 | Val Loss: 0.0179 | R2: -0.0548 | Pearson: 0.2166
Epoch [8/80] | Train Loss: 0.0082 | Val Loss: 0.0155 | R2: 0.0812 | Pearson: 0.3370
Epoch [9/80] | Train Loss: 0.0071 | Val Loss: 0.0194 | R2: -0.1432 | Pearson: 0.4138
Epoch [10/80] | Train Loss: 0.0061 | Val Loss: 0.0187 | R2: -0.0823 | Pearson: 0.3620
Epoch [11/80] | Train Loss: 0.0055 | Val Loss: 0.0136 | R2: 0.1973 | Pearson: 0.4599
Epoch [12/80] | Train Loss: 0.0047 | Val Loss: 0.0138 | R2: 0.1810 | Pearson: 0.4947
Epoch [13/80] | Train Loss: 0.0040 | Val Loss: 0.0290 | R2: -0.6984 | Pearson: 0.3171
Epoch [14/80] | Train Loss: 0.0039 | Val Loss: 0.0241 | R2: -0.4334 | Pearson: 0.4416
Epoch [15/80] | Train Loss: 0.0032 | Val Loss: 0.0156 | R2: 0.0938 | Pearson: 0.5046
Epoch [16/80] | Train Loss: 0.0029 | Val Loss: 0.0139 | R2: 0.1761 | Pearson: 0.4913
Epoch [17/80] | Train Loss: 0.0033 | Val Loss: 0.0176 | R2: -0.0383 | Pearson: 0.4889
Epoch [18/80] | Train Loss: 0.0040 | Val Loss: 0.0210 | R2: -0.2379 | Pearson: 0.4828
Epoch [19/80] | Train Loss: 0.0029 | Val Loss: 0.0183 | R2: -0.0877 | Pearson: 0.4756
Epoch [20/80] | Train Loss: 0.0025 | Val Loss: 0.0160 | R2: 0.0674 | Pearson: 0.4078
Epoch [21/80] | Train Loss: 0.0026 | Val Loss: 0.0161 | R2: 0.0545 | Pearson: 0.5151
Epoch [22/80] | Train Loss: 0.0019 | Val Loss: 0.0134 | R2: 0.2039 | Pearson: 0.5144
Epoch [23/80] | Train Loss: 0.0019 | Val Loss: 0.0158 | R2: 0.0741 | Pearson: 0.5453
Epoch [24/80] | Train Loss: 0.0020 | Val Loss: 0.0147 | R2: 0.1354 | Pearson: 0.5002
Epoch [25/80] | Train Loss: 0.0020 | Val Loss: 0.0141 | R2: 0.1803 | Pearson: 0.5157
Epoch [26/80] | Train Loss: 0.0015 | Val Loss: 0.0177 | R2: -0.0462 | Pearson: 0.4226
Epoch [27/80] | Train Loss: 0.0017 | Val Loss: 0.0143 | R2: 0.1579 | Pearson: 0.5278
Epoch [28/80] | Train Loss: 0.0017 | Val Loss: 0.0121 | R2: 0.2851 | Pearson: 0.5446
Epoch [29/80] | Train Loss: 0.0020 | Val Loss: 0.0148 | R2: 0.1318 | Pearson: 0.5193
Epoch [30/80] | Train Loss: 0.0017 | Val Loss: 0.0121 | R2: 0.2914 | Pearson: 0.5539
Epoch [31/80] | Train Loss: 0.0014 | Val Loss: 0.0131 | R2: 0.2277 | Pearson: 0.5150
Epoch [32/80] | Train Loss: 0.0017 | Val Loss: 0.0140 | R2: 0.2031 | Pearson: 0.5263
Epoch [33/80] | Train Loss: 0.0014 | Val Loss: 0.0146 | R2: 0.1433 | Pearson: 0.5556
Epoch [34/80] | Train Loss: 0.0016 | Val Loss: 0.0177 | R2: -0.0456 | Pearson: 0.5104
Epoch [35/80] | Train Loss: 0.0017 | Val Loss: 0.0137 | R2: 0.1950 | Pearson: 0.4733
Epoch [36/80] | Train Loss: 0.0014 | Val Loss: 0.0414 | R2: -1.4262 | Pearson: 0.3486
Epoch [37/80] | Train Loss: 0.0013 | Val Loss: 0.0160 | R2: 0.0586 | Pearson: 0.4904
Epoch [38/80] | Train Loss: 0.0012 | Val Loss: 0.0119 | R2: 0.3043 | Pearson: 0.5631
Epoch [39/80] | Train Loss: 0.0015 | Val Loss: 0.0122 | R2: 0.2843 | Pearson: 0.5531
Epoch [40/80] | Train Loss: 0.0016 | Val Loss: 0.0142 | R2: 0.1617 | Pearson: 0.5066
Epoch [41/80] | Train Loss: 0.0014 | Val Loss: 0.0129 | R2: 0.2468 | Pearson: 0.5144
Epoch [42/80] | Train Loss: 0.0013 | Val Loss: 0.0139 | R2: 0.1969 | Pearson: 0.5663
Epoch [43/80] | Train Loss: 0.0011 | Val Loss: 0.0128 | R2: 0.2434 | Pearson: 0.5349
Epoch [44/80] | Train Loss: 0.0011 | Val Loss: 0.0122 | R2: 0.2852 | Pearson: 0.5514
Epoch [45/80] | Train Loss: 0.0011 | Val Loss: 0.0122 | R2: 0.2957 | Pearson: 0.5602
Epoch [46/80] | Train Loss: 0.0011 | Val Loss: 0.0128 | R2: 0.2518 | Pearson: 0.5602
Epoch [47/80] | Train Loss: 0.0010 | Val Loss: 0.0119 | R2: 0.2982 | Pearson: 0.5565
Epoch [48/80] | Train Loss: 0.0008 | Val Loss: 0.0124 | R2: 0.2667 | Pearson: 0.5531
Epoch [49/80] | Train Loss: 0.0010 | Val Loss: 0.0137 | R2: 0.1962 | Pearson: 0.5399
Epoch [50/80] | Train Loss: 0.0008 | Val Loss: 0.0118 | R2: 0.3025 | Pearson: 0.5585
Epoch [51/80] | Train Loss: 0.0008 | Val Loss: 0.0125 | R2: 0.2638 | Pearson: 0.5633
Epoch [52/80] | Train Loss: 0.0009 | Val Loss: 0.0127 | R2: 0.2585 | Pearson: 0.5231
Epoch [53/80] | Train Loss: 0.0008 | Val Loss: 0.0116 | R2: 0.3128 | Pearson: 0.5637
Epoch [54/80] | Train Loss: 0.0010 | Val Loss: 0.0117 | R2: 0.3172 | Pearson: 0.5702
Epoch [55/80] | Train Loss: 0.0009 | Val Loss: 0.0156 | R2: 0.0884 | Pearson: 0.4972
Epoch [56/80] | Train Loss: 0.0010 | Val Loss: 0.0114 | R2: 0.3292 | Pearson: 0.5819
Epoch [57/80] | Train Loss: 0.0009 | Val Loss: 0.0125 | R2: 0.2627 | Pearson: 0.5703
Epoch [58/80] | Train Loss: 0.0009 | Val Loss: 0.0118 | R2: 0.3148 | Pearson: 0.5816
Epoch [59/80] | Train Loss: 0.0008 | Val Loss: 0.0117 | R2: 0.3104 | Pearson: 0.5860
Epoch [60/80] | Train Loss: 0.0007 | Val Loss: 0.0114 | R2: 0.3216 | Pearson: 0.5749
Epoch [61/80] | Train Loss: 0.0006 | Val Loss: 0.0115 | R2: 0.3307 | Pearson: 0.5774
Epoch [62/80] | Train Loss: 0.0008 | Val Loss: 0.0114 | R2: 0.3279 | Pearson: 0.5791
Epoch [63/80] | Train Loss: 0.0009 | Val Loss: 0.0112 | R2: 0.3400 | Pearson: 0.5873
Epoch [64/80] | Train Loss: 0.0007 | Val Loss: 0.0115 | R2: 0.3254 | Pearson: 0.5764
Epoch [65/80] | Train Loss: 0.0006 | Val Loss: 0.0115 | R2: 0.3336 | Pearson: 0.5842
Epoch [66/80] | Train Loss: 0.0006 | Val Loss: 0.0115 | R2: 0.3251 | Pearson: 0.5814
Epoch [67/80] | Train Loss: 0.0006 | Val Loss: 0.0110 | R2: 0.3493 | Pearson: 0.5919
Epoch [68/80] | Train Loss: 0.0006 | Val Loss: 0.0116 | R2: 0.3395 | Pearson: 0.5844
Epoch [69/80] | Train Loss: 0.0007 | Val Loss: 0.0113 | R2: 0.3370 | Pearson: 0.5830
Epoch [70/80] | Train Loss: 0.0008 | Val Loss: 0.0117 | R2: 0.3164 | Pearson: 0.5869
Epoch [71/80] | Train Loss: 0.0007 | Val Loss: 0.0116 | R2: 0.3318 | Pearson: 0.5793
Epoch [72/80] | Train Loss: 0.0005 | Val Loss: 0.0114 | R2: 0.3370 | Pearson: 0.5834
Epoch [73/80] | Train Loss: 0.0006 | Val Loss: 0.0113 | R2: 0.3368 | Pearson: 0.5849
Epoch [74/80] | Train Loss: 0.0006 | Val Loss: 0.0114 | R2: 0.3326 | Pearson: 0.5805
Epoch [75/80] | Train Loss: 0.0006 | Val Loss: 0.0113 | R2: 0.3380 | Pearson: 0.5844
Epoch [76/80] | Train Loss: 0.0006 | Val Loss: 0.0114 | R2: 0.3378 | Pearson: 0.5838
Epoch [77/80] | Train Loss: 0.0006 | Val Loss: 0.0113 | R2: 0.3349 | Pearson: 0.5822
Epoch [78/80] | Train Loss: 0.0005 | Val Loss: 0.0113 | R2: 0.3374 | Pearson: 0.5835
Epoch [79/80] | Train Loss: 0.0006 | Val Loss: 0.0112 | R2: 0.3359 | Pearson: 0.5845
Traceback (most recent call last):
  File "train.py", line 128, in <module>
    train_5_fold(dataset, batch_size=16, epochs=80, learning_rate=0.000005, optimizer_type='AdamW', scheduler_type='CosineAnnealingLR', device='cuda')
  File "train.py", line 51, in train_5_fold
    val_loss, r2_score, pearson_corr = evaluate_model(model, val_loader, criterion, device)
  File "train.py", line 108, in evaluate_model
    for images, labels, _ in val_loader:
  File "C:\Users\hyunoh\anaconda3\envs\spine\lib\site-packages\torch\utils\data\dataloader.py", line 630, in __next__
    data = self._next_data()
  File "C:\Users\hyunoh\anaconda3\envs\spine\lib\site-packages\torch\utils\data\dataloader.py", line 673, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "C:\Users\hyunoh\anaconda3\envs\spine\lib\site-packages\torch\utils\data\_utils\fetch.py", line 52, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "C:\Users\hyunoh\anaconda3\envs\spine\lib\site-packages\torch\utils\data\_utils\fetch.py", line 52, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "C:\Users\hyunoh\Documents\Codes\BMD_code\regression_function_classes.py", line 213, in __getitem__
    image = self.process_image(img_path)
  File "C:\Users\hyunoh\Documents\Codes\BMD_code\regression_function_classes.py", line 192, in process_image
    image = self.transform(image=image)["image"]
  File "C:\Users\hyunoh\anaconda3\envs\spine\lib\site-packages\albumentations\core\composition.py", line 349, in __call__
    data = t(**data)
  File "C:\Users\hyunoh\anaconda3\envs\spine\lib\site-packages\albumentations\core\transforms_interface.py", line 125, in __call__
    return self.apply_with_params(params, **kwargs)
  File "C:\Users\hyunoh\anaconda3\envs\spine\lib\site-packages\albumentations\core\transforms_interface.py", line 144, in apply_with_params
    result = target_function(np.require(arg, requirements=["C_CONTIGUOUS"]), **params)
  File "C:\Users\hyunoh\anaconda3\envs\spine\lib\site-packages\albumentations\pytorch\transforms.py", line 42, in apply
    img = np.expand_dims(img, 2)
  File "<__array_function__ internals>", line 200, in expand_dims
  File "C:\Users\hyunoh\anaconda3\envs\spine\lib\site-packages\numpy\lib\shape_base.py", line 600, in expand_dims
    shape = [1 if ax in axis else next(shape_it) for ax in range(out_ndim)]
  File "C:\Users\hyunoh\anaconda3\envs\spine\lib\site-packages\numpy\lib\shape_base.py", line 600, in <listcomp>
    shape = [1 if ax in axis else next(shape_it) for ax in range(out_ndim)]
KeyboardInterrupt
